{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2064bbc1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To be able to access all resources within this notebook, make sure Jupyter is launched at the root of this repo. The path of the notebook should be `/notebook/<repo_root>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Increase notebook width for all embedded cells to display properly\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e18a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "import hydra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288d8db0",
   "metadata": {},
   "source": [
    "# Training an ML planner <a name=\"training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0800a03",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e5324",
   "metadata": {},
   "source": [
    "The following parameter categories define the training protocol which includes the model, metrics, objectives etc.\n",
    "\n",
    "A working example composition of these parameters can be found in the next section.\n",
    "\n",
    "---\n",
    "\n",
    "### ML models\n",
    "\n",
    "Change the training model with `model=X` where `X` is a config yaml defined in the table below. \n",
    "\n",
    "| Model | Description | Config |\n",
    "| --- | --- | --- |\n",
    "| Raster model (CNN) | Raster-based model that uses a CNN backbone to encode ego, agent and map information as raster layers<br />Any (pretrained) backbone from the TIMM library can be used (e.g. ResNet50, EfficientNetB3) | `raster_model` |\n",
    "| Vector model (LaneGCN) | Vector-based model that uses a series of MLPs to encode ego and agent signals, a lane graph to encode vector-map elements and a fusion network to capture lane & agent intra/inter-interactions through attention layers<br />Implementation of LaneGCN paper (\"Learning Lane Graph Representations for Motion Forecasting\") | `vector_model` |\n",
    "| Simple vector model | Toy vector-based model that consumes ego, agent and lane signals through a series of MLPs | `simple_vector_model` |\n",
    "\n",
    "<br />\n",
    "\n",
    "### Training objectives\n",
    "\n",
    "Change the training objectives with `objective=[X, ...]` where `X` is a config yaml defined in the table below. \n",
    "\n",
    "| Objective | Description | Config |\n",
    "| --- | --- | --- |\n",
    "| Imitation objective | Penalizes the predicted trajectory that deviates from the expert demonstration | `imitation_objective` |\n",
    "\n",
    "<br />\n",
    "\n",
    "### Training metrics\n",
    "\n",
    "Change the training objectives with `training_metric=[X, ...]` where `X` is a config yaml defined in the table below. \n",
    "\n",
    "| Metric | Description | Config |\n",
    "| --- | --- | --- |\n",
    "| Average displacement error | RMSE translation error across full predicted trajectory | `avg_displacement_error` |\n",
    "| Average heading error | RMSE heading error across full predicted trajectory | `avg_heading_error` |\n",
    "| Final displacement error | L2 error of predicted trajectory's final pose translation | `final_displacement_error` |\n",
    "| Final heading error | L2 error of predicted trajectory's final pose heading | `final_heading_error` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee66b84",
   "metadata": {},
   "source": [
    "## Prepare the training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05860753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of path with all training configs\n",
    "CONFIG_PATH = '../nuplan/planning/script/config/training'\n",
    "CONFIG_NAME = 'default_training'\n",
    "\n",
    "# Create a temporary directory to store the cache and experiment artifacts\n",
    "SAVE_DIR = Path(tempfile.gettempdir()) / 'tutorial_nuplan_framework'  # optionally replace with persistent dir #NOTES /tmp/tutorial_nuplan_framework\n",
    "EXPERIMENT = 'training_vector_experiment'#'training_raster_experiment'\n",
    "LOG_DIR = str(SAVE_DIR / EXPERIMENT)\n",
    "\n",
    "# Initialize configuration management system\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "hydra.initialize(config_path=CONFIG_PATH)\n",
    "\n",
    "# Compose the configuration\n",
    "cfg = hydra.compose(config_name=CONFIG_NAME, overrides=[\n",
    "    f'group={str(SAVE_DIR)}', #NOTES: default_experiment \n",
    "    f'cache.cache_path={str(SAVE_DIR)}/cache', #NOTES: default_training\n",
    "    f'experiment_name={EXPERIMENT}', #NOTES: default_experiment\n",
    "    'py_func=train', #NOTES: default_training\n",
    "    '+training=training_vector_model',  # raster model that consumes ego, agents and map raster layers and regresses the ego's trajectory\n",
    "    'scenario_builder=nuplan_mini',  # use nuplan mini database #NOTES:default_common\n",
    "    'scenario_filter.limit_total_scenarios=500',  # Choose 500 scenarios to train with #NOTES:default_common\n",
    "    'lightning.trainer.params.accelerator=ddp_spawn',  # ddp is not allowed in interactive environment, using ddp_spawn instead - this can bottleneck the data pipeline, it is recommended to run training outside the notebook #NOTES:nuplan/planning/script/config/training/lightning/default_lightning.yaml\n",
    "    'lightning.trainer.params.max_epochs=10',\n",
    "    'data_loader.params.batch_size=8', #NOTES:nuplan/planning/script/config/training/data_loader/default_data_loader.yaml\n",
    "    'data_loader.params.num_workers=8',\n",
    "    # 'splitter=nuplan',\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162273a1",
   "metadata": {},
   "source": [
    "## Launch tensorboard for visualizing training artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acfc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5edf94",
   "metadata": {},
   "source": [
    "## Launch training (within the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuplan.planning.script.run_training import main as main_train\n",
    "\n",
    "# Run the training loop, optionally inspect training artifacts through tensorboard (above cell)\n",
    "main_train(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd570621",
   "metadata": {},
   "source": [
    "## Launch training (command line - alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad67e5",
   "metadata": {},
   "source": [
    "A training experiment with the above same parameters can be launched alternatively with:\n",
    "```\n",
    "$ python nuplan/planning/script/run_training.py \\\n",
    "    experiment_name=raster_experiment \\\n",
    "    py_func=train \\\n",
    "    +training=training_raster_model \\\n",
    "    scenario_builder=nuplan_mini \\\n",
    "    scenario_filter.limit_total_scenarios=500 \\\n",
    "    lightning.trainer.params.max_epochs=10 \\\n",
    "    data_loader.params.batch_size=8 \\\n",
    "    data_loader.params.num_workers=8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184dc002",
   "metadata": {},
   "source": [
    "# Simulating a planner <a name=\"simulation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49758620",
   "metadata": {},
   "source": [
    "## Open-loop simulation\n",
    "Open-loop simulation aims to evaluate the policy's capabilities to imitate the expert driver's behavior.<br />\n",
    "This is essentially done through log replay as the policy's predictions do not affect the state of the simulation.\n",
    "\n",
    "As the policy is not in full control of the vehicle, this type of simulation can only provide a high-level performance overview.\n",
    "\n",
    "## Closed-loop simulation\n",
    "Conversely, in closed-loop simulation the policy's actions alter the state of the simulation which tries to closely approximate the real-world system.\n",
    "\n",
    "The simulation's feedback loop enables a more in-depth evaluation of the policy as compounding errors can cause future observations to significantly diverge from the ground truth.<br />\n",
    "This is important in measuring distribution shifts introduced due to lack of variance in training examples through pure imitation learning.\n",
    "\n",
    "Closed-loop simulation is further divided into two categories:\n",
    "* ego closed-loop simulation with agents replayed from log (open-loop, non reactive)\n",
    "* ego closed-loop simulation with agents controlled by a rule-based or learned policy (closed-loop, reactive)\n",
    "\n",
    "## Measuring success\n",
    "Measuring the success of a planning task and comparing various planning policies is a complicated effort that involves defining metrics across different vertical dimensions and scenario categories.<br />\n",
    "These metrics include indicators such as vehicle dynamics, traffic rule violations, expert imitation, navigation success etc.<br />\n",
    "Overall, they aim to capture the policy's ability to control the autonomous vehicle safely yet efficiently without compromising the passenger's comfort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04359006",
   "metadata": {},
   "source": [
    "## Simulation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef8382",
   "metadata": {},
   "source": [
    "### Planners\n",
    "\n",
    "Change the planner model with `planner=X` where `X` is a config yaml defined in the table below. \n",
    "\n",
    "| Planner | Description | Config |\n",
    "| --- | --- | --- |\n",
    "| Simple Planner | Naive planner that only plans a straight path | `simple_planner` |\n",
    "| ML Planner | Learning-based planner trained using the nuPlan training framework (see previous section) | `ml_planner` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db903632",
   "metadata": {},
   "source": [
    "## Prepare the simulation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of path with all simulation configs\n",
    "CONFIG_PATH = '../nuplan/planning/script/config/simulation'\n",
    "CONFIG_NAME = 'default_simulation'\n",
    "\n",
    "# Select the planner and simulation challenge\n",
    "PLANNER = 'simple_planner'  # [simple_planner, ml_planner]\n",
    "CHALLENGE = 'open_loop_boxes'  # [open_loop_boxes, closed_loop_nonreactive_agents, closed_loop_reactive_agents]\n",
    "DATASET_PARAMS = [\n",
    "    'scenario_builder=nuplan_mini',  # use nuplan mini database\n",
    "    'scenario_filter=all_scenarios',  # initially select all scenarios in the database\n",
    "    'scenario_filter.scenario_types=[near_multiple_vehicles, on_pickup_dropoff, starting_unprotected_cross_turn, high_magnitude_jerk]',  # select scenario types\n",
    "    'scenario_filter.num_scenarios_per_type=10',  # use 10 scenarios per scenario type\n",
    "]\n",
    "\n",
    "# Name of the experiment\n",
    "EXPERIMENT = 'simulation_simple_experiment'\n",
    "\n",
    "# Initialize configuration management system\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()  # reinitialize hydra if already initialized\n",
    "hydra.initialize(config_path=CONFIG_PATH)\n",
    "\n",
    "# Compose the configuration\n",
    "cfg = hydra.compose(config_name=CONFIG_NAME, overrides=[\n",
    "    f'experiment_name={EXPERIMENT}',\n",
    "    f'group={SAVE_DIR}',\n",
    "    f'planner={PLANNER}',\n",
    "    f'+simulation={CHALLENGE}',\n",
    "    *DATASET_PARAMS,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e79a0a",
   "metadata": {},
   "source": [
    "## Launch simulation (within the notebook) Figure-> figure in metric_summary_callback.py 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7aab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuplan.planning.script.run_simulation import main as main_simulation\n",
    "\n",
    "# Run the simulation loop (real-time visualization not yet supported, see next section for visualization)\n",
    "main_simulation(cfg)\n",
    "\n",
    "# Simple simulation folder for visualization in nuBoard\n",
    "simple_simulation_folder = cfg.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c1fb9",
   "metadata": {},
   "source": [
    "## Launch simulation (command line - alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b23af",
   "metadata": {},
   "source": [
    "A simulation experiment can be launched alternatively with:\n",
    "```\n",
    "$ python nuplan/planning/script/run_simulation.py \\\n",
    "    +simulation=open_loop_boxes \\\n",
    "    planner=simple_planner \\\n",
    "    scenario_builder=nuplan_mini \\\n",
    "    scenario_filter=all_scenarios \\\n",
    "    scenario_filter.scenario_types=\"[near_multiple_vehicles, on_pickup_dropoff, starting_unprotected_cross_turn, high_magnitude_jerk]\" \\\n",
    "    scenario_filter.num_scenarios_per_type=10 \\\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a181f",
   "metadata": {},
   "source": [
    "## Simulate a trained ML planner for comparison\n",
    "\n",
    "Using the same simulation settings as before, we can simulate a pretrained ML planner and compare the two.\n",
    "\n",
    "In this example you can take the model you trained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4dc68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of path with all simulation configs\n",
    "CONFIG_PATH = '../nuplan/planning/script/config/simulation'\n",
    "CONFIG_NAME = 'default_simulation'\n",
    "\n",
    "# Get the checkpoint of the trained model\n",
    "last_experiment = sorted(os.listdir(LOG_DIR))[-1]\n",
    "train_experiment_dir = sorted(Path(LOG_DIR).iterdir())[-1]\n",
    "checkpoint = sorted((train_experiment_dir / 'checkpoints').iterdir())[-1]\n",
    "\n",
    "MODEL_PATH = str(checkpoint).replace(\"=\", \"\\=\")\n",
    "\n",
    "# Name of the experiment\n",
    "EXPERIMENT = 'simulation_raster_experiment'\n",
    "\n",
    "# Initialize configuration management system\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()  # reinitialize hydra if already initialized\n",
    "hydra.initialize(config_path=CONFIG_PATH)\n",
    "\n",
    "# Compose the configuration\n",
    "cfg = hydra.compose(config_name=CONFIG_NAME, overrides=[\n",
    "    f'experiment_name={EXPERIMENT}',\n",
    "    f'group={SAVE_DIR}',\n",
    "    'planner=ml_planner',\n",
    "    'model=raster_model',\n",
    "    'planner.ml_planner.model_config=${model}',  # hydra notation to select model config\n",
    "    f'planner.ml_planner.checkpoint_path={MODEL_PATH}',  # this path can be replaced by the checkpoint of the model trained in the previous section\n",
    "    f'+simulation={CHALLENGE}',\n",
    "    *DATASET_PARAMS,\n",
    "])\n",
    "\n",
    "# Run the simulation loop\n",
    "main_simulation(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ML_planner simulation folder for visualization in nuBoard (next section)\n",
    "ml_planner_simulation_folder = cfg.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a31f9",
   "metadata": {},
   "source": [
    "# Visualizing metrics and scenarios <a name=\"dashboard\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24ae5b",
   "metadata": {},
   "source": [
    "## nuBoard summary\n",
    "\n",
    "Having trained and simulated planners across various scenarios and driving behaviors, it's time to evaluate them:\n",
    "* quantitatively, through common and scenario dependent metrics\n",
    "* qualitatively, through visualization of scenario progression\n",
    "\n",
    "### nuBoard tabs\n",
    "To achieve that, nuBoard has 3 core evaluation tabs:\n",
    "1. Overview - Scalar metrics summary of common and scenario metrics across the following categories:\n",
    "    * Ego dynamics\n",
    "    * Traffic violations\n",
    "    * Expert imitation\n",
    "    * Planning & navigation\n",
    "    * Scenario performance\n",
    "2. Histograms - Histograms over metric statistics for more a granular peek inside each metric focusing on:\n",
    "    * Metric statistics (e.g. min, max, p90)\n",
    "3. Scenarios - Low-level scenario visualizations:\n",
    "    * Time-series progression of a specific metric across a scenario\n",
    "    * Top-down visualization of the scenario across time for comparing predicted vs. expert trajectories\n",
    "\n",
    "In addition, there is a main configuration tab for selecting different simulation files for comparing planners/experiments.\n",
    "\n",
    "<br />\n",
    "\n",
    "**NOTE**: nuBoard is under heavy developement, overall functionality and aesthetics do not represent the final product!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8edb17",
   "metadata": {},
   "source": [
    "## Prepare the nuBoard config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42434f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of path with all nuBoard configs\n",
    "CONFIG_PATH = '../nuplan/planning/script/config/nuboard'\n",
    "CONFIG_NAME = 'default_nuboard'\n",
    "\n",
    "# Initialize configuration management system\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()  # reinitialize hydra if already initialized\n",
    "hydra.initialize(config_path=CONFIG_PATH)\n",
    "\n",
    "# Compose the configuration\n",
    "cfg = hydra.compose(config_name=CONFIG_NAME, overrides=[\n",
    "    'scenario_builder=nuplan_mini',  # set the database (same as simulation) used to fetch data for visualization\n",
    "    f'simulation_path={[simple_simulation_folder, ml_planner_simulation_folder]}',  # nuboard file path(s), if left empty the user can open the file inside nuBoard\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3420d0c5",
   "metadata": {},
   "source": [
    "## Launch nuBoard (open in new tab - recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114e9bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nuplan.planning.script.run_nuboard import main as main_nuboard\n",
    "\n",
    "# Run nuBoard\n",
    "main_nuboard(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177cd444",
   "metadata": {},
   "source": [
    "## Launch nuBoard (embedded within the notebook - alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b6454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_notebook\n",
    "from nuplan.planning.script.run_nuboard import initialize_nuboard\n",
    "\n",
    "# Make sure that the notebook working directory is \"/notebooks\" and that Jupyter was launched at the root of the repo\n",
    "cfg.resource_prefix = '/notebooks/nuplan/planning/metrics/board/'  # pass CSS resources to the notebook\n",
    "\n",
    "# Run the nuBoard\n",
    "output_notebook()\n",
    "nuboard = initialize_nuboard(cfg)\n",
    "show(nuboard.main_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4624979a",
   "metadata": {},
   "source": [
    "## Launch nuBoard (command line - alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557156ac",
   "metadata": {},
   "source": [
    "nuBoard can be launched alternatively with:\n",
    "```\n",
    "$ python nuplan/planning/script/run_nuboard.py\n",
    "```\n",
    "\n",
    "Simulation files (.nuboard) can be selected under the configuration tab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuplan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "48ca0acd1969550dd67c85929230cf3c94789603436ff0154e5c8e935c2207d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
